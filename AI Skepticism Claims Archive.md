# Archive of AI skepticism claims that aged poorly

**50 documented predictions** about AI failure, limitations, and hype—from major publications, named researchers, and credentialed experts—that subsequent developments have contradicted. This archive spans 1954–2024, organized by category with exact quotes, sources, and verification details.

---

## Market and investment skepticism

These predictions warned that AI investments would fail, stocks would crash, or an "AI winter" was imminent—just before historic rallies and unprecedented adoption.

### 1. BMO Capital Markets NVIDIA downgrade

**Claim:** Analyst downgraded NVIDIA from "market perform" to "underperform," predicting the gaming business would see "marked deceleration."

**Source:** Ambrish Srivastava, BMO Capital Markets analyst

**Date:** February 23, 2017

**URL:** https://www.cnbc.com/2017/11/13/nvidia-shares-double-analyst-says-bearish-call-did-not-work-out.html

**Category:** market

**Why it aged poorly:** NVIDIA stock rose **115%** from the downgrade through November 2017. Srivastava publicly admitted: "We have been reluctant to change our view, but now recognize that our underperform call did not work out."

---

### 2. "AI Winter Is Well On Its Way"

**Claim:** "Predicting the AI winter is like predicting a stock market crash—impossible to tell precisely when it happens, but almost certain that it will at some point... In my opinion there are such signs of a huge decline in deep learning (and probably in AI in general) already visible."

**Source:** Filip Piekniewski, AI researcher and critic

**Date:** May 28, 2018

**URL:** https://blog.piekniewski.info/2018/05/28/ai-winter-is-well-on-its-way/

**Category:** market

**Why it aged poorly:** The post went viral (250,000+ views) and was picked up by Bloomberg, Forbes, and BBC. Instead of an AI winter, ChatGPT launched in 2022 and triggered the largest AI boom in history. NVIDIA became a **$3 trillion** company. Total AI investment reached $375 billion by 2025.

---

### 3. AI Winter prediction for 2020

**Claim:** "I think another AI Winter is coming... I think this skepticism trend is going to intensify in 2019 and will go mainstream as soon as 2020."

**Source:** Thomas Nield, tech writer, Medium/HackerNoon

**Date:** January 2019

**URL:** https://medium.com/hackernoon/is-another-ai-winter-coming-ac552669e58c

**Category:** market

**Why it aged poorly:** 2020 brought GPT-3's release and accelerating investment, not winter. By July 2024, AI companies represented **49.4%** of S&P 500 market capitalization.

---

### 4. Morgan Stanley and Needham NVIDIA downgrades

**Claim:** Multiple analysts downgraded NVIDIA following Q3 2018 weakness. Bank of America dropped it from its "best stocks to buy" list.

**Source:** Morgan Stanley, Needham, Bank of America analysts

**Date:** November 2018–January 2019

**URL:** https://investorplace.com/2019/01/rehashed-news-nvidia-stock-simg/

**Category:** market

**Why it aged poorly:** NVIDIA was "49% off all-time highs" in January 2019. It then gained over **4,000%** from those lows to become the world's most valuable company in 2024.

---

### 5. Jim Cramer's NVIDIA warning

**Claim:** "NVIDIA got it so wrong no one will trust CEO for a while" and warned shares "likely have further to fall."

**Source:** Jim Cramer, CNBC "Mad Money" host

**Date:** November 2018

**URL:** https://www.cnbc.com/video/2018/11/16/cramer-nvidia-got-it-so-wrong-no-one-will-trust-ceo-for-a-while.html

**Category:** market

**Why it aged poorly:** Cramer later noted his NVIDIA recommendation was "up 42,000% since his first recommendation." The stock became one of the greatest winners in market history.

---

### 6. Quantitative managers skeptical of machine learning

**Claim:** "Just because you can create more inputs doesn't mean it will be valid."

**Source:** Ryan Caldwell, CIO of Chiron Investment Management (formerly managed $45B at Waddell & Reed)

**Date:** April 2017

**URL:** https://www.institutionalinvestor.com/article/b1505q8nnxr58t/quants-skeptical-of-big-data-machine-learning-hype

**Category:** market

**Why it aged poorly:** AI-driven strategies became central to modern asset management. Machine learning now dominates portfolio construction, risk management, and algorithmic trading.

---

### 7. Michael Burry's "Sell" call

**Claim:** One-word tweet: "Sell." Also warned of "the greatest speculative bubble of all time in all things."

**Source:** Michael Burry, Scion Asset Management founder, "Big Short" fame

**Date:** February 2023 (and 2021–2022 warnings)

**URL:** https://www.irishtimes.com/your-money/2025/12/01/ai-bubble-big-short-investor-michael-burrys-bold-calls-often-miss-the-mark/

**Category:** market

**Why it aged poorly:** Buying the S&P 500 would have yielded **34% six-month returns**. The Nasdaq surged 21%+ in months following his call. Burry admitted he was "wrong" two months later.

---

### 8. Seeking Alpha NVIDIA crash prediction

**Claim:** "Nvidia Corporation's stock price gain of +45% since August makes a steep sell-off in 2024 more likely, not less. Overvaluation stats and the cyclical nature of Nvidia's business model are reasons for serious concern."

**Source:** Paul Franke, Seeking Alpha contributor (nationally ranked stock picker for 30 years)

**Date:** Late 2023

**URL:** https://seekingalpha.com/article/4666890-nvidia-was-my-late-summer-crash-call-wrong-or-early

**Category:** market

**Why it aged poorly:** Instead of crashing, NVIDIA gained **91.3%** the following year. The author later asked if his crash call was "wrong or early."

---

### 9. Forrester's AI market prediction

**Claim:** AI market would reach **$1.2 trillion** by 2020.

**Source:** Forrester Research

**Date:** 2016

**URL:** https://slate.com/technology/2021/05/artificial-intelligence-moonshots-usually-fail.html

**Category:** market

**Why it aged poorly:** By 2020, Forrester reported the AI market was only **$17 billion**—about 1.4% of their prediction. Off by 98.6%.

---

### 10. Ethereum 2.0 risk warning for NVIDIA

**Claim:** NVIDIA faces "imminent" risk from Ethereum 2.0 transition that would crash GPU demand.

**Source:** Paulo Santos, Seeking Alpha contributor

**Date:** October 2021

**URL:** https://seekingalpha.com/article/4457550-nvidia-the-imminent-ethereum-2-0-risk

**Category:** market

**Why it aged poorly:** While Ethereum did transition to proof-of-stake in 2022, the AI boom more than compensated. NVIDIA became the world's most valuable company, demonstrating AI demand far outweighed crypto mining losses.

---

## Capability skepticism

Specific predictions that AI couldn't achieve particular tasks—many proven wrong within months or years of being made.

### 11. Go mastery "a decade away"

**Claim:** "I think maybe ten years... But I do not like to make predictions."

**Source:** Rémi Coulom, computer scientist and creator of Crazy Stone Go program

**Date:** May 2014

**URL:** https://www.wired.com/2014/05/the-mystery-of-go-the-ancient-game-that-computers-still-cant-win/

**Category:** capability

**Why it aged poorly:** AlphaGo defeated world champion Lee Sedol in **March 2016**—just 22 months later. DeepMind called this "a decade earlier than experts predicted."

---

### 12. "Computers would never defeat top humans at Go"

**Claim:** "Before AlphaGo, some researchers had claimed that computers would never defeat top humans at Go."

**Source:** Multiple AI researchers (documented expert consensus)

**Date:** Pre-2015

**URL:** https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol

**Category:** capability

**Why it aged poorly:** AlphaGo defeated the world's top Go player 4-1 in March 2016. AlphaGo Zero later achieved **100-0** against the original AlphaGo.

---

### 13. Go intuition "impossible for computers"

**Claim:** Go requires human intuition that computers fundamentally lack, with computers handicapped 4+ stones against professionals.

**Source:** Multiple Go experts and AI researchers consensus

**Date:** Pre-2015

**URL:** https://spartanideas.msu.edu/2014/05/26/the-mystery-of-go/

**Category:** capability

**Why it aged poorly:** After defeat, top player Ke Jie remarked: "After humanity spent thousands of years improving our tactics, computers tell us that humans are completely wrong."

---

### 14. "Any work a man can do" in 20 years

**Claim:** "Machines will be capable, within twenty years, of doing any work a man can do."

**Source:** Herbert Simon, Nobel Laureate economist, Carnegie Mellon professor

**Date:** 1965

**URL:** https://quoteinvestigator.com/2021/03/04/ai-solved/

**Category:** capability

**Why it aged poorly:** By 1985—and even 2025—machines cannot perform most human work. This overly optimistic prediction shows forecasting difficulty from both directions.

---

### 15. Human-level AI in "3-8 years"

**Claim:** "In from three to eight years we will have a machine with the general intelligence of an average human being. I mean a machine that will be able to read Shakespeare, grease a car, play office politics, tell a joke, have a fight."

**Source:** Marvin Minsky, co-founder of MIT AI Lab, Life Magazine interview

**Date:** 1970

**URL:** https://slate.com/technology/2021/05/artificial-intelligence-moonshots-usually-fail.html

**Category:** capability

**Why it aged poorly:** By 1982, Minsky himself admitted: "The AI problem is one of the hardest science has ever undertaken." 55+ years later, AGI remains unrealized.

---

### 16. AI problems "substantially solved" within a generation

**Claim:** "Within a generation... the problem of creating 'artificial intelligence' will be substantially solved."

**Source:** Marvin Minsky, in "Computation: Finite and Infinite Machines"

**Date:** 1967

**URL:** https://quoteinvestigator.com/2021/03/04/ai-solved/

**Category:** capability

**Why it aged poorly:** A generation later (late 1980s–1990s), AI entered its second "winter" with funding cuts and failed expert systems.

---

### 17. Machine translation "perfected in 3-5 years"

**Claim:** Language translation programs would be perfected in three to five years.

**Source:** Georgetown-IBM demonstration team

**Date:** 1954

**URL:** https://slate.com/technology/2021/05/artificial-intelligence-moonshots-usually-fail.html

**Category:** capability

**Why it aged poorly:** The 1966 ALPAC Report concluded machine translation was "slower, less accurate, and more expensive than human translation." Quality translation took until the 2010s–2020s with neural networks—**60+ years** later.

---

### 18. Chess champion "within ten years"

**Claim:** "Within ten years a digital computer will be the world's chess champion."

**Source:** Herbert Simon and Allen Newell

**Date:** 1958

**URL:** https://web.eecs.umich.edu/~kuipers/opinions/AI-progress.html

**Category:** capability

**Why it aged poorly:** It took until **1997** (39 years) for IBM's Deep Blue to defeat Garry Kasparov.

---

### 19. Reverse-engineer the human brain in 10 years

**Claim:** His research group would reverse-engineer the human brain using a supercomputer to simulate 86 billion neurons within a decade.

**Source:** Henry Markram, neuroscientist, TED talk

**Date:** 2009

**URL:** https://slate.com/technology/2021/05/artificial-intelligence-moonshots-usually-fail.html

**Category:** capability

**Why it aged poorly:** The €1.3 billion Human Brain Project "crashed in 2015." The brain remains far from reverse-engineered as of 2025.

---

### 20. Perceptrons "limited"—neural networks can't learn

**Claim:** Simple neural networks couldn't solve basic problems like XOR, casting doubt on their potential for complex tasks.

**Source:** Marvin Minsky and Seymour Papert, "Perceptrons" book

**Date:** 1969

**URL:** https://en.wikipedia.org/wiki/AI_winter

**Category:** capability

**Why it aged poorly:** While technically correct about single-layer perceptrons, this contributed to an AI winter for neural networks. Deep learning breakthroughs (2012+) proved neural networks extraordinarily capable.

---

### 21. Lighthill Report: AI failed its "grandiose objectives"

**Claim:** AI has failed to achieve its "grandiose objectives" and nothing being done in AI could not be done in other sciences.

**Source:** Sir James Lighthill, British government-commissioned report

**Date:** 1973

**URL:** https://en.wikipedia.org/wiki/AI_winter

**Category:** capability

**Why it aged poorly:** While accurate about 1973 limitations, the report's pessimism contributed to devastating funding cuts. Later breakthroughs demonstrated AI could achieve remarkable capabilities.

---

### 22. John Zimmer's driverless prediction

**Claim:** "A majority of [Lyft] trips would be in fully driverless vehicles by 2021."

**Source:** John Zimmer, Lyft President, Medium post

**Date:** September 2016

**URL:** https://www.cnbc.com/2022/10/11/lyft-president-still-thinks-driverless-cars-will-dominate-ride-share.html

**Category:** capability

**Why it aged poorly:** As of 2025, humans still drive nearly all Lyft vehicles. Lyft sold its autonomous vehicle division to Toyota in 2021 for $550 million after failing to meet this goal.

---

### 23. Elon Musk's Tesla full autonomy prediction

**Claim:** Tesla would achieve full autonomy, able to drive "from Los Angeles to New York without human intervention" within a year.

**Source:** Elon Musk

**Date:** 2016

**URL:** https://research.contrary.com/deep-dive/the-trillion-dollar-battle-to-build-a-robotaxi-empire

**Category:** capability

**Why it aged poorly:** As of 2025, Tesla's FSD (Supervised) only reaches Level 2 autonomy. The LA-to-NY autonomous drive hasn't happened. Musk also predicted one million robotaxis by 2020.

---

### 24. Turing Test passed by year 2000

**Claim:** Computers might achieve a 30% pass rate in the Turing Test by 2000.

**Source:** Alan Turing, "Computing Machinery and Intelligence"

**Date:** 1950

**URL:** https://plato.stanford.edu/entries/turing-test/

**Category:** capability

**Why it aged poorly:** ChatGPT, which likely meets or beats that rate, wasn't released until **2022**—22 years after Turing's predicted date.

---

### 25. Geoffrey Hinton's radiologist prediction

**Claim:** "We should stop training radiologists now. It's just completely obvious that within five years deep learning is going to do better than radiologists."

**Source:** Geoffrey Hinton, "Godfather of AI," Turing Award winner

**Date:** November 2016

**URL:** https://newrepublic.com/article/187203/ai-radiology-geoffrey-hinton-nobel-prediction

**Category:** capability

**Why it aged poorly:** As of 2024, "the number of radiologists who have been replaced by AI is approximately zero" (STAT). Mayo Clinic's radiology staff grew **55%**. Even Yann LeCun said: "We knew then, and we know now, that he was wrong."

---

### 26. MarketWatch robots prediction

**Claim:** Robots will take over 90% of jobs in maintenance and groundskeeping in 10-20 years.

**Source:** MarketWatch article

**Date:** 2017

**URL:** https://www.technologyreview.com/2017/10/06/241837/the-seven-deadly-sins-of-ai-predictions/

**Category:** capability

**Why it aged poorly:** As Rodney Brooks noted: "How many robots are currently operational in those jobs? Zero. How many realistic demonstrations have there been? Zero." As of 2025, these jobs remain largely human-performed.

---

### 27. Watson healthcare transformation

**Claim:** IBM Watson would achieve 30-50% productivity improvement for nurses, 5-9% reduction in healthcare costs.

**Source:** McKinsey report (influenced by IBM Watson hype)

**Date:** 2016–2017

**URL:** https://slate.com/technology/2021/05/artificial-intelligence-moonshots-usually-fail.html

**Category:** capability

**Why it aged poorly:** A 2020 Mayo Clinic/Harvard survey gave Watson-based clinical decision support a median score of **11/100**, with only 14% recommending it. IBM pulled Watson from drug discovery.

---

## AGI and fundamental limits

Academic arguments that AGI is impossible, deep learning has hit walls, or current approaches face insurmountable barriers.

### 28. "Deep Learning Is Hitting a Wall"

**Claim:** "We may already be running into scaling limits in deep learning, perhaps already approaching a point of diminishing returns... research from DeepMind and elsewhere on models even larger than GPT-3 have shown that scaling starts to falter on some measures."

**Source:** Gary Marcus, Professor Emeritus of Psychology and Neural Science, NYU

**Date:** March 10, 2022

**URL:** https://nautil.us/deep-learning-is-hitting-a-wall-238440/

**Category:** agi

**Why it aged poorly:** GPT-4 (March 2023) showed significant improvements over GPT-3, particularly in reasoning. Though Marcus now claims vindication citing late-2024 scaling reports, the timing and specifics were contested.

---

### 29. "Deep learning must be supplemented"

**Claim:** "I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence."

**Source:** Gary Marcus, NYU Professor; ArXiv paper "Deep Learning: A Critical Appraisal"

**Date:** January 2, 2018

**URL:** https://arxiv.org/abs/1801.00631

**Category:** agi

**Why it aged poorly:** GPT-3 and GPT-4 achieved far more through pure deep learning than the 2018 paper predicted. However, concerns about hallucinations have proven prescient.

---

### 30. "GPT-3 Has No Idea What It's Talking About"

**Claim:** Demonstrated GPT-3 giving absurd responses like claiming cranberry-grape juice would kill you.

**Source:** Ernest Davis (NYU) & Gary Marcus, MIT Technology Review

**Date:** 2020

**URL:** Referenced in Nautilus article on deep learning limits

**Category:** agi

**Why it aged poorly:** GPT-4 solved **15 of the problems** Marcus had used to demonstrate GPT-3's failures. While hallucinations persist, capability improvements have been substantial.

---

### 31. Dreyfus: "Disembodied machines cannot mimic higher mental functions"

**Claim:** "Human intelligence and expertise depend primarily on yet-to-be understood informal and unconscious processes rather than symbolic manipulation... these essentially human skills cannot be fully captured in formal rules."

**Source:** Hubert Dreyfus, Professor of Philosophy, UC Berkeley

**Date:** 1972 ("What Computers Can't Do"), updated 1992

**URL:** https://mitpress.mit.edu/9780262540674/what-computers-still-cant-do/

**Category:** agi

**Why it aged poorly:** Deep learning achieved perception tasks (image/speech recognition) that Dreyfus believed impossible. Though his critique of symbolic AI proved correct.

---

### 32. Dreyfus's four philosophical assumptions dooming AI

**Claim:** Critiqued four assumptions: brains as computer hardware; minds performing discrete computations; all activity formalizable; reality consisting of atomic facts.

**Source:** Hubert Dreyfus, "Alchemy and AI" (1965), "What Computers Can't Do" (1972)

**Date:** 1965–1992

**URL:** https://en.wikipedia.org/wiki/Hubert_Dreyfus%27s_views_on_artificial_intelligence

**Category:** agi

**Why it aged poorly:** The AI community largely ignored Dreyfus, but neural networks bypassed his rule-based critiques entirely—achieving results through statistical learning rather than formal rules.

---

### 33. Penrose: "Human consciousness is non-algorithmic"

**Claim:** "The quality of conscious understanding is something essentially distinct from computation... computers today are unable to have intelligence because they are algorithmically deterministic systems."

**Source:** Roger Penrose, Emeritus Rouse Ball Professor of Mathematics, Oxford; Nobel Prize in Physics 2020

**Date:** 1989 ("The Emperor's New Mind")

**URL:** https://en.wikipedia.org/wiki/The_Emperor%27s_New_Mind

**Category:** agi

**Why it aged poorly:** Current AI systems perform impressive cognitive tasks without consciousness, suggesting consciousness may not be necessary for practical intelligence. Penrose's quantum microtubule theory remains unverified.

---

### 34. Penrose: "AI can never achieve true understanding"

**Claim:** "What I'm saying—and this is my leap of imagination which people boggle at—I'm saying what's going on in the brain must be taking advantage not just of quantum mechanics, but where it goes wrong."

**Source:** Roger Penrose, Oxford University, Nautilus interview

**Date:** 2017

**URL:** https://nautil.us/roger-penrose-on-why-consciousness-does-not-compute-236591/

**Category:** agi

**Why it aged poorly:** AI has achieved tasks requiring apparent "understanding" (medical diagnosis, legal reasoning, creative writing) without any quantum effects. Max Tegmark calculated quantum decoherence times in the brain are too fast to support Penrose's theory.

---

### 35. Chomsky: "The False Promise of ChatGPT"

**Claim:** "The human mind is not, like ChatGPT and its ilk, a lumbering statistical engine for pattern matching, gorging on hundreds of terabytes of data... These programs cannot explain the rules of English syntax, which renders their predictions always superficial and dubious."

**Source:** Noam Chomsky (MIT/U. Arizona), Ian Roberts (Cambridge), Jeffrey Watumull; The New York Times

**Date:** March 8, 2023

**URL:** https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html

**Category:** agi

**Why it aged poorly:** ChatGPT reached **200+ million** weekly users by late 2024. LLMs demonstrated impressive language capabilities that challenge Chomsky's universal grammar framework, even without formal grammatical explanation.

---

### 36. Chomsky: "LLMs cannot tell us anything about language"

**Claim:** "The LLM systems are designed in such a way that they cannot tell us anything about language, learning, or other aspects of cognition, a matter of principle, irremediable."

**Source:** Noam Chomsky, Chomsky.info interview

**Date:** May 3, 2023

**URL:** https://chomsky.info/20230503-2/

**Category:** agi

**Why it aged poorly:** Researchers argue LLMs have revealed insights about language statistics and distributional semantics. The philosophical position about "understanding" remains debated, but practical utility has been demonstrated.

---

### 37. Kurzweil's human-level AI by 2029

**Claim:** "Computers will have human-level intelligence and will have all of the intellectual and emotional capabilities of humans, including 'the ability to tell a joke, to be funny, to be romantic, to be loving, to be sexy'" by 2029.

**Source:** Ray Kurzweil, "The Singularity Is Near"

**Date:** 2005/2014

**URL:** https://slate.com/technology/2021/05/artificial-intelligence-moonshots-usually-fail.html

**Category:** agi

**Why it aged poorly:** With 2029 only 4 years away, no AI system approaches human-level general intelligence or emotional capabilities. Kurzweil increasingly talks about 2045 instead.

---

### 38. LeCun: "AI systems lack the general common sense of a cat"

**Claim:** "AI systems still lack the general common sense of a cat... A true AI revolution won't happen until machines acquire common sense."

**Source:** Yann LeCun, VP & Chief AI Scientist at Meta, NYU Silver Professor, Turing Award winner

**Date:** 2019–2024 (repeated claim)

**URL:** https://www.newworldai.com/power-limits-of-deep-learning-yann-lecun/

**Category:** agi

**Why it aged poorly:** LeCun's claim about common sense limitations remains largely accurate—current LLMs struggle with basic physical reasoning. However, his timeline predictions ("two, five, twenty years") have been challenged by rapid progress in other domains.

---

### 39. Chollet: "Current deep learning can only do local generalization"

**Claim:** "Despite our progress on machine perception, we are still very far from human-level AI: our models can only perform local generalization... The most important problem for AI today is abstraction and reasoning."

**Source:** François Chollet, Senior Staff Engineer at Google, creator of Keras; TIME 100 Most Influential in AI (2024)

**Date:** 2017–2019

**URL:** https://fchollet.com/

**Category:** agi

**Why it aged poorly:** Chollet's ARC benchmark remains unsolved by LLMs (GPT-4 scores ~10% vs. humans at 95%+), supporting his thesis about generalization limits. His predictions appear increasingly validated rather than contradicted.

---

## Dismissive takes

General dismissals of AI as "just hype," characterizing capabilities as useless or unimpressive.

### 40. "Stochastic Parrots" paper

**Claim:** LLMs "haphazardly stitch together sequences of linguistic forms...according to probabilistic information about how they combine, but without any reference to meaning."

**Source:** Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, Margaret Mitchell; ACM FAccT Conference

**Date:** March 2021

**URL:** https://dl.acm.org/doi/10.1145/3442188.3445922

**Category:** dismissive

**Why it aged poorly:** GPT-4's performance on complex reasoning tasks (>90th percentile on Bar Exam, 93% on MATH Olympiad problems) suggests capabilities beyond mere "parroting." The term became 2023 AI-related "Word of the Year."

---

### 41. Bender: "LLM output correct just by chance"

**Claim:** "We have to keep in mind that when [LLM] output is correct, that is just by chance. You might as well be asking a Magic 8 ball, right?"

**Source:** Emily Bender, Professor of Linguistics, University of Washington; Harvey Mudd College lecture

**Date:** November 12, 2024

**URL:** https://tsl.news/emily-bender-on-ai-as-a-stochastic-parrot/

**Category:** dismissive

**Why it aged poorly:** Comparing LLMs to a "Magic 8 ball" understates empirically demonstrated capabilities. LLMs are used for medical diagnosis assistance, legal research, and code generation—applications where random outputs would be immediately apparent.

---

### 42. Doctorow: "AI hype bubble is the new crypto bubble"

**Claim:** "AI has all the hallmarks of a classic pump-and-dump... ChatGPT is best understood as a sophisticated form of autocomplete—not our new robot overlord."

**Source:** Cory Doctorow, sci-fi author and tech journalist, Pluralistic blog

**Date:** March 9, 2023

**URL:** https://pluralistic.net/2023/03/09/autocomplete-worshippers/

**Category:** dismissive

**Why it aged poorly:** AI-related stocks accounted for **75%** of S&P 500 returns since ChatGPT launched. A 2024 McKinsey survey found **65%** of organizations regularly using generative AI, nearly double from 2023.

---

### 43. Marcus: "GPT-3 is a Bullshit Artist"

**Claim:** "I was writing pieces about GPT-3 being a bullshit artist in 2020." Also predicted in August 2024: "The AI bubble will collapse... It's going to be days or weeks from now, not months."

**Source:** Gary Marcus, NYU Professor Emeritus

**Date:** 2020 (GPT-3 criticism); August 2024 (bubble prediction)

**URL:** https://spectrum.ieee.org/gary-marcus; https://x.com/GaryMarcus/status/1819525054537126075

**Category:** dismissive

**Why it aged poorly:** GPT-4 solved **15 of the problems** Marcus used to demonstrate GPT-3's failures. His August 2024 prediction of collapse in "days or weeks" has not materialized as of December 2025.

---

### 44. Ted Chiang: "ChatGPT Is a Blurry JPEG of the Web"

**Claim:** "[AI] hallucinations are compression artifacts... they are plausible enough that identifying them requires comparing them against the originals."

**Source:** Ted Chiang, acclaimed science fiction author, The New Yorker

**Date:** February 2023

**URL:** https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web

**Category:** dismissive

**Why it aged poorly:** The "blurry JPEG" metaphor suggests LLMs merely lossy-compress existing information. This doesn't account for emergent capabilities like solving novel math problems, generating original code, or creative applications.

---

### 45. "ChatGPT is 80% useless at work"

**Claim:** "It's not there yet. Not even close... it's way too unreliable to build into your working processes right now."

**Source:** Various tech commentators on Medium

**Date:** Throughout 2023

**URL:** https://killdozer.medium.com/chatgpt-is-80-useless-at-work-beware-the-linkedin-ai-snake-oil-f54908463b79

**Category:** dismissive

**Why it aged poorly:** By 2024–2025, GitHub Copilot was used by millions of developers, Klarna reported replacing hundreds of customer service agents with AI, and enterprise adoption became mainstream.

---

### 46. Salganik: "ChatGPT didn't help me do peer review at all"

**Claim:** "There is a huge gap between writing funny instructions for removing food from home electronics and doing scientific research... ChatGPT didn't help me do peer review at all; not one little bit."

**Source:** Matthew Salganik, Princeton University researcher

**Date:** March 2023

**URL:** https://freedom-to-tinker.com/2023/03/08/can-chatgpt-and-its-successors-go-from-cool-to-tool/

**Category:** dismissive

**Why it aged poorly:** By 2024, academic journals explicitly addressed AI use in peer review. Tools like Elicit and Consensus were built specifically for research applications. Nature reported AI being used in research workflows.

---

### 47. "AI Art is Not Real Art"

**Claim:** "AI 'Art' is not REAL art. It is soulless image generation that is hindering real artists... AI art is like fool's gold, shiny and pretty on the outside, worthless on the inside."

**Source:** Various artists and critics in artist forums

**Date:** 2022–2023

**URL:** https://www.artistforum.com/threads/my-opinion-on-ai-art.63728/

**Category:** dismissive

**Why it aged poorly:** AI image generation has been adopted by major studios for concept art, advertising agencies, and millions of users. AI-generated images have won art competitions and appeared in major publications.

---

### 48. AI as a "bad word" in 1991

**Claim/Historical Context:** "When I graduated with my PhD in AI and ML in '91, AI was literally a bad word. No company would consider hiring somebody who was in AI."

**Source:** Usama Fayyad, Executive Director for Experiential AI, Northeastern University

**Date:** Reflecting on 1991

**URL:** https://aidegreeguide.com/blog/the-history-of-ai-is-marked-with-missed-forecasts-and-overly-ambitious-predictions/

**Category:** dismissive

**Why it aged poorly:** The AI winter of the late 1980s–early 1990s led to complete dismissal of AI's commercial viability. Those who bet against AI's eventual resurgence were proven dramatically wrong by the 2010s deep learning revolution.

---

## Historical perspective and patterns

### 49. Expert systems "very specialized and very few"

**Claim:** "The kinds of applications for which expert systems are likely to improve on human experts are very specialized and very few."

**Source:** Drew McDermott, AI researcher (1984 AAAI panel warning about AI hype)

**Date:** 1984

**URL:** https://www.openphilanthropy.org/research/what-should-we-learn-from-past-ai-forecasts/

**Category:** capability

**Why it aged poorly:** While expert systems did collapse, modern AI systems have exceeded human expert performance in medical diagnosis, image recognition, game playing, code generation, and language translation.

---

### 50. Minsky: "Computers won't even keep us as pets"

**Claim:** "Within 10 years computers won't even keep us as pets."

**Source:** Marvin Minsky

**Date:** ~1967

**URL:** https://www.americanheritage.com/myth-artificial-intelligence

**Category:** capability

**Why it aged poorly:** By 1977, computers could not approximate human intelligence, let alone surpass it. This prediction dramatically overestimated AI progress—a cautionary tale about forecasting in either direction.

---

## Key patterns and observations

**Recurring themes in failed predictions:**

- **Timeline compression**: Predictions from 1955–1970 were typically off by 30–50+ years. Expert predictions clustered around "15–25 years from now" regardless of when made.

- **"Never" claims proven wrong rapidly**: Go predictions from 2014 were contradicted within 18 months by AlphaGo.

- **Market skepticism at inflection points**: Multiple analysts downgraded NVIDIA in 2017–2019 just before 4,000%+ gains.

- **Dismissive framing vs. practical utility**: "Just autocomplete" and "stochastic parrot" characterizations failed to anticipate emergent capabilities and widespread adoption.

- **AI winter predictions during AI spring**: 2018–2019 AI winter predictions preceded the largest AI boom in history.

**Important caveats:**

Some current AI skepticism (Jim Covello at Goldman Sachs, Daron Acemoglu at MIT, ongoing scaling concerns) has not yet been proven right or wrong. The jury remains out on whether current AI investment levels will generate adequate returns. This archive focuses on predictions that **have** aged poorly given subsequent developments—not on ongoing debates where outcomes remain uncertain.

**Sources used:** CNBC, The New York Times, MIT Technology Review, Wired, Bloomberg, Fortune, The New Yorker, Nautilus, Slate, ArXiv, Wikipedia, academic papers, Seeking Alpha, institutional investor publications, and primary source interviews.